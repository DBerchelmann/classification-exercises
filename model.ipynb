{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "\n",
    "- What is your baseline prediction? <b> predicting survivability </b>\n",
    "\n",
    "- What is your baseline accuracy? <b> 61.6%</b> remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "\n",
    "- Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample) <b> complete</b>\n",
    "\n",
    "- Evaluate your in-sample results using the model score, confusion matrix, and classification report. <b> complete</b>\n",
    "\n",
    "- Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support. <b>complete, see classification report</b>\n",
    "\n",
    "- Run through steps 2-4 using a different max_depth value. <b> complete, depth value of 3 works best</b> \n",
    "\n",
    "- Which model performs better on your in-sample data? <b> model with depth of 3</b>\n",
    "\n",
    "- Which model performs best on your out-of-sample data, the validate set? <b> The model with a depth of 3</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/davidberchelmann/codeup-data-science/classification-exercises/titanic_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def handle_missing_values(df):\n",
    "    return df.assign(\n",
    "        embark_town=df.embark_town.fillna('Other'),\n",
    "        embarked=df.embarked.fillna('O'),\n",
    "    )\n",
    "\n",
    "def remove_columns(df):\n",
    "    return df.drop(columns=['deck'])\n",
    "\n",
    "def encode_embarked(df):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(df.embarked)\n",
    "    return df.assign(embarked_encode = encoder.transform(df.embarked))\n",
    "\n",
    "def prep_titanic_data(df):\n",
    "    df = df\\\n",
    "        .pipe(handle_missing_values)\\\n",
    "        .pipe(remove_columns)\\\n",
    "        .pipe(encode_embarked)\n",
    "    return df\n",
    "\n",
    "def train_validate_test_split(df, seed=123):\n",
    "    train_and_validate, test = train_test_split(\n",
    "        df, test_size=0.2, random_state=seed, stratify=df.survived\n",
    "    )\n",
    "    train, validate = train_test_split(\n",
    "        train_and_validate,\n",
    "        test_size=0.3,\n",
    "        random_state=seed,\n",
    "        stratify=train_and_validate.survived,\n",
    "    )\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  passenger_id  survived  pclass     sex   age  sibsp  parch  \\\n",
       "0           0             0         0       3    male  22.0      1      0   \n",
       "1           1             1         1       1  female  38.0      1      0   \n",
       "2           2             2         1       3  female  26.0      0      0   \n",
       "3           3             3         1       1  female  35.0      1      0   \n",
       "4           4             4         0       3    male  35.0      0      0   \n",
       "\n",
       "      fare embarked  class deck  embark_town  alone  \n",
       "0   7.2500        S  Third  NaN  Southampton      0  \n",
       "1  71.2833        C  First    C    Cherbourg      0  \n",
       "2   7.9250        S  Third  NaN  Southampton      1  \n",
       "3  53.1000        S  First    C  Southampton      0  \n",
       "4   8.0500        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out data columns first before cleaning. Get rid of 'Unnamed', 'passenger_id', 'pclass', 'age', 'sibsp', 'parch'\n",
    "# rename survived column to 'yes' 'no' and use as target variable\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data followed by creating train/validate/test function\n",
    "\n",
    "def clean_titanic():\n",
    "    '''\n",
    "    clean_titanic will take a dataframe acquired as df and remove columns that are:\n",
    "    duplicates,\n",
    "    have too many nulls,\n",
    "    and will fill in smaller amounts of nulls in embark_town\n",
    "    encode sex and embark_town columns\n",
    "    \n",
    "    return: single cleaned dataframe\n",
    "    '''\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    dropcols = ['age', 'deck', 'embarked', 'Unnamed: 0', 'passenger_id', 'pclass', 'sibsp', 'parch']\n",
    "    df.drop(columns=dropcols, inplace=True)\n",
    "    df['embark_town'] = df['embark_town'].fillna('Southampton')\n",
    "    dummies = pd.get_dummies(df[['embark_town', 'sex', 'class']], drop_first=True)\n",
    "    return pd.concat([df, dummies], axis=1)\n",
    "\n",
    "\n",
    "def train_validate_test_split(df, seed=123):\n",
    "    train_and_validate, test = train_test_split(\n",
    "        df, test_size=0.2, random_state=seed, stratify=df.survived\n",
    "    )\n",
    "    train, validate = train_test_split(\n",
    "        train_and_validate,\n",
    "        test_size=0.3,\n",
    "        random_state=seed,\n",
    "        stratify=train_and_validate.survived,\n",
    "    )\n",
    "    return train, validate, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data using function from above\n",
    "\n",
    "df = clean_titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename survied column to using a no/yes in place of 0/1\n",
    "\n",
    "#df['survived'] = df['survived'].replace([0,1],['no', 'yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex     fare  class  embark_town  alone  \\\n",
       "0         0    male   7.2500  Third  Southampton      0   \n",
       "1         1  female  71.2833  First    Cherbourg      0   \n",
       "2         1  female   7.9250  Third  Southampton      1   \n",
       "3         1  female  53.1000  First  Southampton      0   \n",
       "4         0    male   8.0500  Third  Southampton      1   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  sex_male  class_Second  \\\n",
       "0                       0                        1         1             0   \n",
       "1                       0                        0         0             0   \n",
       "2                       0                        1         0             0   \n",
       "3                       0                        1         0             0   \n",
       "4                       0                        1         1             0   \n",
       "\n",
       "   class_Third  \n",
       "0            1  \n",
       "1            0  \n",
       "2            1  \n",
       "3            0  \n",
       "4            1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns to make sure changes have been made\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived     sex      fare   class  embark_town  alone  \\\n",
       "583         0    male   40.1250   First    Cherbourg      1   \n",
       "165         1    male   20.5250   Third  Southampton      0   \n",
       "50          0    male   39.6875   Third  Southampton      0   \n",
       "259         1  female   26.0000  Second  Southampton      0   \n",
       "306         1  female  110.8833   First    Cherbourg      1   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  sex_male  class_Second  \\\n",
       "583                       0                        0         1             0   \n",
       "165                       0                        1         1             0   \n",
       "50                        0                        1         1             0   \n",
       "259                       0                        1         0             1   \n",
       "306                       0                        0         0             0   \n",
       "\n",
       "     class_Third  \n",
       "583            0  \n",
       "165            1  \n",
       "50             1  \n",
       "259            0  \n",
       "306            0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "# stratifying means we're making representative datasets between train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, seed=123)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our X inputs and y target variable for each split\n",
    "X_train = train.drop(columns=['survived', 'sex', 'embark_town', 'class'])\n",
    "y_train = train.survived # labeled data == supervise algorithm\n",
    "\n",
    "X_validate = validate.drop(columns=['survived', 'sex', 'embark_town', 'class'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived', 'sex', 'embark_town', 'class'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived     sex      fare   class  embark_town  alone  \\\n",
       "583         0    male   40.1250   First    Cherbourg      1   \n",
       "165         1    male   20.5250   Third  Southampton      0   \n",
       "50          0    male   39.6875   Third  Southampton      0   \n",
       "259         1  female   26.0000  Second  Southampton      0   \n",
       "306         1  female  110.8833   First    Cherbourg      1   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  sex_male  class_Second  \\\n",
       "583                       0                        0         1             0   \n",
       "165                       0                        1         1             0   \n",
       "50                        0                        1         1             0   \n",
       "259                       0                        1         0             1   \n",
       "306                       0                        0         0             0   \n",
       "\n",
       "     class_Third  \n",
       "583            0  \n",
       "165            1  \n",
       "50             1  \n",
       "259            0  \n",
       "306            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check training data\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived  sex   \n",
       "0         male      468\n",
       "          female     81\n",
       "1         female    233\n",
       "          male      109\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('survived').sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived  sex   \n",
       "0         male      265\n",
       "          female     42\n",
       "1         female    133\n",
       "          male       58\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('survived').sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a blank, new Decision Tree model\n",
    "# Be sure to set the max_depth argument\n",
    "# clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=123)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's train our model on the training data\n",
    "# fitting == training the model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"most_frequent\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    498\n",
       "Name: most_frequent, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['most_frequent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_decision_tree.pdf'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the model so it can explain itself!\n",
    "\n",
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True, format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll make a set of predictions using this trained model\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probabilities for each class\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_accuracy = (train.survived == train.most_frequent).mean()\n",
    "baseline_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the model\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = clf.score(X_train, y_train)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_train, y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(y_train, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(class_report).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_df = pd.DataFrame(conf, columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])\n",
    "\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf was trained on X_train, y_train\n",
    "# To evaluate the model trained on new data, the arguments coming into .score()\n",
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate this model on out-of-sample data\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the classification model trained on train data to make predictions on validate data\n",
    "y_pred = clf.predict(X_validate)\n",
    "y_pred[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare actual y values from validate to predictions based on X_validate\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_male = train[train.sex_male > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare = not_male[not_male.fare <= 18.275]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alone = fare[fare.alone <=.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alone.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model so it can explain itself!\n",
    "\n",
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True, format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run new model with depth of 2\n",
    "clf1 = DecisionTreeClassifier(max_depth=2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's train our model on the training data\n",
    "# fitting == training the model\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf1.predict(X_train)\n",
    "y_pred[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probabilities for each class\n",
    "y_pred_proba = clf1.predict_proba(X_train)\n",
    "y_pred_proba[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf was trained on X_train, y_train\n",
    "# To evaluate the model trained on new data, the arguments coming into .score()\n",
    "clf1.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate this model on out-of-sample data\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf1.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Random Forest Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Continue working in your model file with titanic data to do the following:\n",
    "\n",
    "- Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "- Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "- Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "- Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n",
    "- What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "- After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48108242 0.03828706 0.01592272 0.02759923 0.33183925 0.02041746\n",
      " 0.08485187]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.94\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[302   5]\n",
      " [ 27 164]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       307\n",
      "           1       0.97      0.86      0.91       191\n",
      "\n",
      "    accuracy                           0.94       498\n",
      "   macro avg       0.94      0.92      0.93       498\n",
      "weighted avg       0.94      0.94      0.93       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 0.77\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to calculate these metrics\n",
    "def get_metrics_binary(rf):\n",
    "    '''\n",
    "    get_metrics_binary takes in a confusion matrix (cnf) for a binary classifier and prints out metrics based on\n",
    "    values in variables named X_train, y_train, and y_pred.\n",
    "    \n",
    "    return: a classification report as a transposed DataFrame\n",
    "    '''\n",
    "    accuracy = rf.score(X_train, y_train)\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)).T\n",
    "    conf = confusion_matrix(y_train, y_pred)\n",
    "    tpr = conf[1][1] / conf[1].sum()\n",
    "    fpr = conf[0][1] / conf[0].sum()\n",
    "    tnr = conf[0][0] / conf[0].sum()\n",
    "    fnr = conf[1][0] / conf[1].sum()\n",
    "    print(f'''\n",
    "    The accuracy for our model is {accuracy:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "    return class_report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.9357\n",
      "    The True Positive Rate is 0.859, The False Positive Rate is 0.0163,\n",
      "    The True Negative Rate is 0.984, and the False Negative Rate is 0.141\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.917933</td>\n",
       "      <td>0.983713</td>\n",
       "      <td>0.949686</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.970414</td>\n",
       "      <td>0.858639</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.935743</td>\n",
       "      <td>0.935743</td>\n",
       "      <td>0.935743</td>\n",
       "      <td>0.935743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.944174</td>\n",
       "      <td>0.921176</td>\n",
       "      <td>0.930398</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.938061</td>\n",
       "      <td>0.935743</td>\n",
       "      <td>0.934891</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.917933  0.983713  0.949686  307.000000\n",
       "1              0.970414  0.858639  0.911111  191.000000\n",
       "accuracy       0.935743  0.935743  0.935743    0.935743\n",
       "macro avg      0.944174  0.921176  0.930398  498.000000\n",
       "weighted avg   0.938061  0.935743  0.934891  498.000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report1 = get_metrics_binary(rf)\n",
    "class_report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=5, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf2.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report2 = get_metrics_binary(rf2)\n",
    "\n",
    "class_report2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for our validation sets\n",
    "y_val_pred_1 = rf.predict(validate.drop(columns=['survived', 'sex', 'embark_town', 'class']))\n",
    "y_val_pred_2 = rf2.predict(validate.drop(columns=['survived', 'sex', 'embark_town', 'class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get validation accuracy\n",
    "accuracy_v_1 = rf.score(validate.drop(columns=['survived', 'sex', 'embark_town', 'class']), validate.survived)\n",
    "accuracy_v_2 = rf2.score(validate.drop(columns=['survived', 'sex', 'embark_town', 'class']), validate.survived)\n",
    "accuracy_v_3 = rf3.score(validate.drop(columns=['survived', 'sex', 'embark_town', 'class']), validate.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_v_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_v_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_v_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "    <b>The first model performed best on the in sample data which had a depth of 10 and min samples of 1.</b>\n",
    "    \n",
    "- After making a few models, which one has the best performance (or closest metrics) on both train and validate?\n",
    "\n",
    "    <b>The second model performed slightly better on validate (1 percentage point) while the first model had a higher performance on train data.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf3.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf3.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf3.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report3 = get_metrics_binary(rf3)\n",
    "\n",
    "class_report3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------------\\n Model #1')\n",
    "\n",
    "print(class_report1) \n",
    "\n",
    "print('------------------------\\n Model #2')\n",
    "\n",
    "print(class_report2)\n",
    "\n",
    "print('------------------------\\n Model #3')\n",
    "\n",
    "print(class_report3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "- Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "- Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "- Run through steps 2-4 setting k to 10\n",
    "\n",
    "- Run through setps 2-4 setting k to 20\n",
    "\n",
    "- What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "- Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note to self: when running your inputs and target variables, you can't have 'most_frequent' as a column in X_train or else you validate and test won't work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our X inputs and y target variable for each split\n",
    "X_train = train.drop(columns=['survived', 'sex', 'embark_town', 'class', 'most_frequent'])\n",
    "y_train = train.survived # labeled data == supervise algorithm\n",
    "\n",
    "X_validate = validate.drop(columns=['survived', 'sex', 'embark_town', 'class'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived', 'sex', 'embark_town', 'class'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's train the model\n",
    "\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.819\n"
     ]
    }
   ],
   "source": [
    "# Let's check the accuracy\n",
    "accuracy = knn.score(X_train, y_train)\n",
    "print(f\"accuracy is {accuracy:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on test set: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Let's see how well this model performs on out of sample data!\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the predictions from the model\n",
    "y_pred1 = knn.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_binary(knn):\n",
    "    '''\n",
    "    get_metrics_binary takes in a confusion matrix (cnf) for a binary classifier and prints out metrics based on\n",
    "    values in variables named X_train, y_train, and y_pred.\n",
    "    \n",
    "    return: a classification report as a transposed DataFrame\n",
    "    '''\n",
    "    accuracy = knn.score(X_train, y_train)\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)).T\n",
    "    conf = confusion_matrix(y_train, y_pred)\n",
    "    tpr = conf[1][1] / conf[1].sum()\n",
    "    fpr = conf[0][1] / conf[0].sum()\n",
    "    tnr = conf[0][0] / conf[0].sum()\n",
    "    fnr = conf[1][0] / conf[1].sum()\n",
    "    print(f'''\n",
    "    The accuracy for our model is {accuracy:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "    return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.8193\n",
      "    The True Positive Rate is 0.723, The False Positive Rate is 0.121,\n",
      "    The True Negative Rate is 0.879, and the False Negative Rate is 0.277\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.835913</td>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788571</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.819277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.812242</td>\n",
       "      <td>0.800996</td>\n",
       "      <td>0.805621</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.817756</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.817622</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.835913  0.879479  0.857143  307.000000\n",
       "1              0.788571  0.722513  0.754098  191.000000\n",
       "accuracy       0.819277  0.819277  0.819277    0.819277\n",
       "macro avg      0.812242  0.800996  0.805621  498.000000\n",
       "weighted avg   0.817756  0.819277  0.817622  498.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report_knn = get_metrics_binary(knn)\n",
    "\n",
    "class_report_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79       132\n",
      "           1       0.68      0.52      0.59        82\n",
      "\n",
      "    accuracy                           0.72       214\n",
      "   macro avg       0.71      0.69      0.69       214\n",
      "weighted avg       0.72      0.72      0.72       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check our other classification metrics\n",
    "print(classification_report(y_validate, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.789\n"
     ]
    }
   ],
   "source": [
    "# Let's check the accuracy\n",
    "accuracy = knn.score(X_train, y_train)\n",
    "print(f\"accuracy is {accuracy:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on test set: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Let's see how well this model performs on out of sample data!\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the predictions from the model\n",
    "y_pred1 = knn.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_binary(knn):\n",
    "    '''\n",
    "    get_metrics_binary takes in a confusion matrix (cnf) for a binary classifier and prints out metrics based on\n",
    "    values in variables named X_train, y_train, and y_pred.\n",
    "    \n",
    "    return: a classification report as a transposed DataFrame\n",
    "    '''\n",
    "    accuracy = knn.score(X_train, y_train)\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)).T\n",
    "    conf = confusion_matrix(y_train, y_pred)\n",
    "    tpr = conf[1][1] / conf[1].sum()\n",
    "    fpr = conf[0][1] / conf[0].sum()\n",
    "    tnr = conf[0][0] / conf[0].sum()\n",
    "    fnr = conf[1][0] / conf[1].sum()\n",
    "    print(f'''\n",
    "    The accuracy for our model is {accuracy:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "    return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.7892\n",
      "    The True Positive Rate is 0.628, The False Positive Rate is 0.111,\n",
      "    The True Negative Rate is 0.889, and the False Negative Rate is 0.372\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.793605</td>\n",
       "      <td>0.889251</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.628272</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.789157</td>\n",
       "      <td>0.789157</td>\n",
       "      <td>0.789157</td>\n",
       "      <td>0.789157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.786413</td>\n",
       "      <td>0.758762</td>\n",
       "      <td>0.767181</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.788088</td>\n",
       "      <td>0.789157</td>\n",
       "      <td>0.783842</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.793605  0.889251  0.838710  307.000000\n",
       "1              0.779221  0.628272  0.695652  191.000000\n",
       "accuracy       0.789157  0.789157  0.789157    0.789157\n",
       "macro avg      0.786413  0.758762  0.767181  498.000000\n",
       "weighted avg   0.788088  0.789157  0.783842  498.000000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report_knn_10 = get_metrics_binary(knn)\n",
    "\n",
    "class_report_knn_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79       132\n",
      "           1       0.68      0.52      0.59        82\n",
      "\n",
      "    accuracy                           0.72       214\n",
      "   macro avg       0.71      0.69      0.69       214\n",
      "weighted avg       0.72      0.72      0.72       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check our other classification metrics\n",
    "print(classification_report(y_validate, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=20)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.743\n"
     ]
    }
   ],
   "source": [
    "# Let's check the accuracy\n",
    "accuracy = knn.score(X_train, y_train)\n",
    "print(f\"accuracy is {accuracy:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on test set: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Let's see how well this model performs on out of sample data!\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the predictions from the model\n",
    "y_pred1 = knn.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_binary(knn):\n",
    "    '''\n",
    "    get_metrics_binary takes in a confusion matrix (cnf) for a binary classifier and prints out metrics based on\n",
    "    values in variables named X_train, y_train, and y_pred.\n",
    "    \n",
    "    return: a classification report as a transposed DataFrame\n",
    "    '''\n",
    "    accuracy = knn.score(X_train, y_train)\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)).T\n",
    "    conf = confusion_matrix(y_train, y_pred)\n",
    "    tpr = conf[1][1] / conf[1].sum()\n",
    "    fpr = conf[0][1] / conf[0].sum()\n",
    "    tnr = conf[0][0] / conf[0].sum()\n",
    "    fnr = conf[1][0] / conf[1].sum()\n",
    "    print(f'''\n",
    "    The accuracy for our model is {accuracy:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "    return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.743\n",
      "    The True Positive Rate is 0.55, The False Positive Rate is 0.137,\n",
      "    The True Negative Rate is 0.863, and the False Negative Rate is 0.45\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.754986</td>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.805471</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.549738</td>\n",
       "      <td>0.621302</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.742972</td>\n",
       "      <td>0.742972</td>\n",
       "      <td>0.742972</td>\n",
       "      <td>0.742972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.734636</td>\n",
       "      <td>0.706465</td>\n",
       "      <td>0.713386</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.739376</td>\n",
       "      <td>0.742972</td>\n",
       "      <td>0.734836</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.754986  0.863192  0.805471  307.000000\n",
       "1              0.714286  0.549738  0.621302  191.000000\n",
       "accuracy       0.742972  0.742972  0.742972    0.742972\n",
       "macro avg      0.734636  0.706465  0.713386  498.000000\n",
       "weighted avg   0.739376  0.742972  0.734836  498.000000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report_knn_20 = get_metrics_binary(knn)\n",
    "\n",
    "class_report_knn_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.77       132\n",
      "           1       0.64      0.50      0.56        82\n",
      "\n",
      "    accuracy                           0.70       214\n",
      "   macro avg       0.68      0.66      0.67       214\n",
      "weighted avg       0.69      0.70      0.69       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check our other classification metrics\n",
    "print(classification_report(y_validate, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = []\n",
    "for k in range(1, 10):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)    \n",
    "    knn.fit(X_train, y_train)\n",
    "    accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    test_accuracy = knn.score(X_test, y_test)\n",
    "    output = {}\n",
    "    output[\"k\"] = k\n",
    "    output[\"accuracy\"] = accuracy\n",
    "    output[\"validate_accuracy\"] = validate_accuracy\n",
    "    output[\"test_accuracy\"] = test_accuracy\n",
    "    outcomes.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = []\n",
    "for k in range(1, 20):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)    \n",
    "    knn.fit(X_train, y_train)\n",
    "    accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    test_accuracy = knn.score(X_test, y_test)\n",
    "    output = {}\n",
    "    output[\"k\"] = k\n",
    "    output[\"accuracy\"] = accuracy\n",
    "    output[\"validate_accuracy\"] = validate_accuracy\n",
    "    output[\"test_accuracy\"] = test_accuracy\n",
    "    outcomes.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
